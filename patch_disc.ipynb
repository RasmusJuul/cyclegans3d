{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = torch.load('style_vangogh.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numparams is 11,388,698\n"
     ]
    }
   ],
   "source": [
    "x = sum(t.numel() for t in config.values())\n",
    "print(f\"Numparams is {x:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): DiscConvBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (1): DiscConvBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (2): DiscConvBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (3): DiscConvBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class DiscConvBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, stride=2, is_first=False):\n",
    "        super(DiscConvBlock, self).__init__()\n",
    "        block = (\n",
    "            nn.Conv2d(channels_in, channels_out, kernel_size=4, stride=stride, padding=1),\n",
    "            nn.InstanceNorm2d(channels_out),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "        )\n",
    "        if is_first: # remove the second element\n",
    "            block = block[0], block[1]\n",
    "        self.block = nn.Sequential(*block)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "x = torch.rand(2, 3, 256, 256)\n",
    "\"\"\"\n",
    "    Note that there is instance norm for first block\n",
    "    and the stride is 2 for first 3 blocks and 1 for the last block.\n",
    "    This is followed by a huge conv layer with again stride=1\n",
    "\"\"\"\n",
    "model = nn.Sequential(\n",
    "    DiscConvBlock(3, 64, is_first=True),\n",
    "    DiscConvBlock(64, 128),\n",
    "    DiscConvBlock(128, 256),\n",
    "    DiscConvBlock(256, 512, stride=1),\n",
    "    # last block uses 1 channel conv\n",
    "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLayerDiscriminator(nn.Module):\n",
    "    \"\"\"Defines a PatchGAN discriminator\"\"\"\n",
    "\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.InstanceNorm2d):\n",
    "        \"\"\"Construct a PatchGAN discriminator\n",
    "        Parameters:\n",
    "            input_nc (int)  -- the number of channels in input images\n",
    "            ndf (int)       -- the number of filters in the last conv layer\n",
    "            n_layers (int)  -- the number of conv layers in the discriminator\n",
    "            norm_layer      -- normalization layer\n",
    "        \"\"\"\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        use_bias = True\n",
    "\n",
    "        kw = 4\n",
    "        padw = 1\n",
    "        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        for n in range(1, n_layers):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            sequence += [\n",
    "                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
    "                norm_layer(ndf * nf_mult),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]\n",
    "\n",
    "        nf_mult_prev = nf_mult\n",
    "        nf_mult = min(2 ** n_layers, 8)\n",
    "        sequence += [\n",
    "            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
    "            norm_layer(ndf * nf_mult),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n",
    "        self.model = nn.Sequential(*sequence)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Standard forward.\"\"\"\n",
    "        return self.model(input)\n",
    "    \n",
    "test = NLayerDiscriminator(input_nc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 30, 30])\n",
      "2,764,737\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 256, 256)\n",
    "with torch.no_grad():\n",
    "    print(model(x).shape)\n",
    "    \n",
    "y = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{y:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 30, 30])\n",
      "2,764,737\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 256, 256)\n",
    "with torch.no_grad():\n",
    "    print(test(x).shape)\n",
    "    \n",
    "y = sum(p.numel() for p in test.parameters() if p.requires_grad)\n",
    "print(f\"{y:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
