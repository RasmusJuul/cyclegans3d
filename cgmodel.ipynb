{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guestimating batchsize\n",
    "- Generator size = 770\n",
    "- Discriminator size = 75\n",
    "\n",
    "Therefore Cycle gan will need:\n",
    "\n",
    "(770 + 75) * 2 = 1690 MB for float64 batch_size 1\n",
    "\n",
    "ie, for float32 will have 845 MB for batch_size 1\n",
    "\n",
    "for 4GB GPU we can have 4096/845 = 4.85 => max batch_size is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "import itertools\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import PatchDiscriminator, ResnetGenerator\n",
    "from src.UnpairedDataset import UnpairedDataset\n",
    "from src.image_pool import ImagePool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_requires_grad(nets, requires_grad):\n",
    "    for net in nets:\n",
    "        for param in net.parameters():\n",
    "            param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGan(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # generator pair\n",
    "        self.genX = ResnetGenerator.get_generator()\n",
    "        self.genY = ResnetGenerator.get_generator()\n",
    "        \n",
    "        # discriminator pair\n",
    "        self.disX = PatchDiscriminator.get_model()\n",
    "        self.disY = PatchDiscriminator.get_model()\n",
    "        \n",
    "        self.lm = 10.0\n",
    "        self.fakePoolA = ImagePool()\n",
    "        self.fakePoolB = ImagePool()\n",
    "        self.genLoss = None\n",
    "        self.disLoss = None\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optG = Adam(\n",
    "            itertools.chain(self.genX.parameters(), self.genY.parameters()),\n",
    "            lr=2e-4, betas=(0.5, 0.999))\n",
    "        \n",
    "        optD = Adam(\n",
    "            itertools.chain(self.disX.parameters(), self.disY.parameters()),\n",
    "            lr=2e-4, betas=(0.5, 0.999))\n",
    "        \n",
    "        gamma = lambda epoch: 1 - max(0, epoch + 1 - 100) / 101\n",
    "        schG = LambdaLR(optG, lr_lambda=gamma)\n",
    "        schD = LambdaLR(optD, lr_lambda=gamma)\n",
    "        return [optG, optD], [schG, schD]\n",
    "\n",
    "    def generator_training_step(self, imgA, imgB):        \n",
    "        \"\"\"cycle images - using only generator nets\"\"\"\n",
    "        fakeB = self.genX(imgA)\n",
    "        cycledA = self.genY(fakeB)\n",
    "        \n",
    "        fakeA = self.genY(imgB)\n",
    "        cycledB = self.genX(fakeA)\n",
    "        \n",
    "        sameB = self.genX(imgB)\n",
    "        sameA = self.genY(imgA)\n",
    "        \n",
    "        # generator genX must fool discrim disY\n",
    "        predFakeB = self.disY(fakeB)\n",
    "        bceGenB = F.binary_cross_entropy_with_logits(predFakeB, torch.ones_like(predFakeB))\n",
    "        \n",
    "        # generator genY must fool discrim disX\n",
    "        predFakeA = self.disX(fakeA)\n",
    "        bceGenA = F.binary_cross_entropy_with_logits(predFakeA, torch.ones_like(predFakeA))\n",
    "        \n",
    "        # compute extra losses\n",
    "        identityLoss = F.l1_loss(sameA, imgA) + F.l1_loss(sameB, imgB)\n",
    "        \n",
    "        # compute cycleLosses\n",
    "        cycleLoss = F.l1_loss(cycledA, imgA) + F.l1_loss(cycledB, imgB)\n",
    "        \n",
    "        # gather all losses\n",
    "        extraLoss = cycleLoss + 0.5 * identityLoss\n",
    "        self.genLoss = bceGenA + bceGenB + self.lm * extraLoss\n",
    "        self.log('gen_loss', self.genLoss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        # store detached generated images\n",
    "        self.fakeA = fakeA.detach()\n",
    "        self.fakeB = fakeB.detach()\n",
    "        \n",
    "        return self.genLoss\n",
    "    \n",
    "    def discriminator_training_step(self, imgA, imgB):\n",
    "        \"\"\"Update Discriminator\"\"\"        \n",
    "        fakeA = self.fakePoolA.query(self.fakeA)\n",
    "        fakeB = self.fakePoolB.query(self.fakeB)\n",
    "        \n",
    "        # disX takes input for type A photos and predicts if they are fake(1) or not(0)\n",
    "        predRealA = self.disX(imgA)\n",
    "        bceRealA = F.binary_cross_entropy_with_logits(predRealA, torch.zeros_like(predRealA))\n",
    "        \n",
    "        predFakeA = self.disX(fakeA)\n",
    "        bceFakeA = F.binary_cross_entropy_with_logits(predFakeA, torch.ones_like(predFakeA))\n",
    "        \n",
    "        # disY takes input for type B photos and predicts if they are fake(1) or not(0)\n",
    "        predRealB = self.disY(imgB)\n",
    "        bceRealB = F.binary_cross_entropy_with_logits(predRealB, torch.zeros_like(predRealB))\n",
    "        \n",
    "        predFakeB = self.disY(fakeB)\n",
    "        bceFakeB = F.binary_cross_entropy_with_logits(predFakeB, torch.ones_like(predFakeB))\n",
    "        \n",
    "        # gather all losses\n",
    "        self.disLoss = 0.5 * (bceFakeA + bceRealA + bceFakeB + bceRealB)\n",
    "        self.log('dis_loss', self.disLoss.item(), on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return self.disLoss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        imgA, imgB = batch['A'], batch['B']\n",
    "        discriminator_requires_grad = (optimizer_idx==1)\n",
    "        set_requires_grad([self.disX, self.disY], discriminator_requires_grad)\n",
    "        \n",
    "        if optimizer_idx == 0:\n",
    "            return self.generator_training_step(imgA, imgB)\n",
    "        else:\n",
    "            return self.discriminator_training_step(imgA, imgB)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(286, Image.BICUBIC),\n",
    "        transforms.RandomCrop(256),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([.5, .5, .5], [.5, .5, .5])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([.5, .5, .5], [.5, .5, .5])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1072 images of trainA and 6287 images of trainB\n"
     ]
    }
   ],
   "source": [
    "root = 'C:/Users/Deepak H R/Desktop/data/monet2photo/'\n",
    "train = UnpairedDataset(root, 'train', transforms=data_transforms['train'])\n",
    "train = DataLoader(train, batch_size=4, shuffle=True)\n",
    "batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CycleGan()\n",
    "trainer = pl.Trainer(gpus=1, precision=16, max_epochs=1)\n",
    "trainer.fit(model, train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
