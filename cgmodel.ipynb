{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import PatchDiscriminator, ResnetGenerator\n",
    "from src.UnpairedDataset import UnpairedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PatchDiscriminator.get_model()\n",
    "# summary(model, input_size=(3, 256, 256), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src import ResnetGenerator\n",
    "# model = ResnetGenerator.get_generator()\n",
    "# summary(model, input_size=(3, 256, 256), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guestimating batchsize possible\n",
    "- Generator size = 770\n",
    "- Discriminator size = 75\n",
    "\n",
    "Therefore Cycle gan will need:\n",
    "\n",
    "(770 + 75) * 2 = 1690 MB for float64 batch_size 1\n",
    "\n",
    "ie, for float32 will have 845 MB for batch_size 1\n",
    "\n",
    "for 4GB GPU we can have 4096/845 = 4.85 => max batch_size is 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ganLoss(imgA, isRealA, fakeB, isFakeB, cycledA):\n",
    "    \"\"\"Computes the loass\n",
    "        isRealA, isFakeB -> Tensors of shape [b 1 30 30]\n",
    "        imgA, fakeB, cycledA -> Tensors of shape [b 3 256 256]\n",
    "    \"\"\"\n",
    "    \n",
    "    # generator must fool the discriminator\n",
    "    discLoss = F.binary_cross_entropy_with_logits(isFakeB, torch.ones_like(isFakeB))\n",
    "    \n",
    "    # cycledA and imgA must be same\n",
    "    cycleLoss = F.l1_loss(cycledA, imgA)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGan(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # generator pair\n",
    "        self.genX = ResnetGenerator.get_generator()\n",
    "        self.genY = ResnetGenerator.get_generator()\n",
    "        \n",
    "        # discriminator pair\n",
    "        self.disX = PatchDiscriminator.get_model()\n",
    "        self.disY = PatchDiscriminator.get_model()\n",
    "        \n",
    "        # losses defined here\n",
    "        \n",
    "    def cycle_image(self, imgA, name='A'):\n",
    "        genX, genY = self.genX, self.genY\n",
    "        disX, disY = self.disX, self.disY\n",
    "        \n",
    "        if name=='B': # swap the nets\n",
    "            genX, genY = genY, genX\n",
    "            disX, disY = disY, disX\n",
    "        \n",
    "        # reinforce that A is a real image according to disX\n",
    "        isRealA = disX(imgA)\n",
    "        \n",
    "        # fakeB must be such that disY must be fooled\n",
    "        fakeB = genX(imgA)\n",
    "        isFakeB = disY(fakeB)\n",
    "        \n",
    "        # cycledA should be such that disX must be fooled\n",
    "        cycledA = genY(fakeB)\n",
    "        \n",
    "        L = \"isRealA, fakeB, isFakeB, cycledA\".split(\", \")\n",
    "        V = isRealA, fakeB, isFakeB, cycledA\n",
    "        for name, val in zip(L, V):\n",
    "            print(name, val.shape)\n",
    "        return isRealA, fakeB, isFakeB, cycledA\n",
    "        \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Dataloader will feed batch like so\n",
    "        {\n",
    "            'A': imgA, 'pathA': pathA,\n",
    "            'B': imgB, 'pathB': pathB\n",
    "        }\n",
    "        \n",
    "        genX: A->fakeB, genY: B->fakeA\n",
    "        \"\"\"\n",
    "        imgA, imgB = batch['A'], batch['B']\n",
    "        \n",
    "        # we get 8 return values\n",
    "        isRealA, fakeB, isFakeB, cycledA = self.cycle_image(imgA, name='A')\n",
    "        isRealB, fakeA, isFakeA, cycledB = self.cycle_image(imgB, name='B')\n",
    "        \n",
    "        # ensure tint of the image is maintained using\n",
    "        # identity loss |A - sameA| + |B - sameB|\n",
    "        # this also ensures that generators dont change the image too much\n",
    "        sameB = self.genX(B)\n",
    "        sameA = self.genY(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1072 images of trainA and 6287 images of trainB\n"
     ]
    }
   ],
   "source": [
    "root = 'C:/Users/Deepak H R/Desktop/data/monet2photo/'\n",
    "train = UnpairedDataset(root, 'train', transforms=data_transforms['train'])\n",
    "train = DataLoader(train, batch_size=2, shuffle=True)\n",
    "batch = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isRealA torch.Size([2, 1, 30, 30])\n",
      "fakeB torch.Size([2, 3, 256, 256])\n",
      "isFakeB torch.Size([2, 1, 30, 30])\n",
      "cycledA torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "model = CycleGan()\n",
    "with torch.no_grad():\n",
    "    isRealA, fakeB, isFakeB, cycledA = model.cycle_image(batch['A'], name='A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A', 'pathA', 'B', 'pathB'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
